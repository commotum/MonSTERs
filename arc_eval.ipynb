{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Visualization\u001b[39;00m\n\u001b[32m     26\u001b[39m ARC_COLOR_MAP = mcolors.ListedColormap([\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m#000000\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# symbol_0: black\u001b[39;00m\n\u001b[32m     28\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m#0074D9\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# symbol_1: blue\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m#870C25\u001b[39m\u001b[33m\"\u001b[39m   \u001b[38;5;66;03m# symbol_9: brown\u001b[39;00m\n\u001b[32m     37\u001b[39m ])\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m obj = \u001b[43mall_preds\u001b[49m  \u001b[38;5;66;03m# or load the raw file you saved before building all_preds\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(obj))\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(obj.keys()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mkeys\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m obj)\n",
      "\u001b[31mNameError\u001b[39m: name 'all_preds' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "from dataset.common import inverse_dihedral_transform\n",
    "\n",
    "\n",
    "# DATASET_PATH = \"data/arc-mini-aug-100\"  # ARC-mini\n",
    "# DATASET_PATH = \"data/arc-aug-1000\"  # ARC-1\n",
    "DATASET_PATH = \"data/arc-2-aug-1000\"  # ARC-2\n",
    "\n",
    "CHECKPOINT_PATH = \"checkpoints/HRM-checkpoint-ARC-2/checkpoint\" #\"checkpoints/Arc-aug-1000 ACT-torch/HierarchicalReasoningModel_ACTV1 amphibian-turaco/step_414456\"\n",
    "\n",
    "\n",
    "PAD_PUZZLE_IDENTIFIER = 0\n",
    "\n",
    "# Visualization\n",
    "ARC_COLOR_MAP = mcolors.ListedColormap([\n",
    "    \"#000000\",  # symbol_0: black\n",
    "    \"#0074D9\",  # symbol_1: blue\n",
    "    \"#FF4136\",  # symbol_2: red\n",
    "    \"#2ECC40\",  # symbol_3: green\n",
    "    \"#FFDC00\",  # symbol_4: yellow\n",
    "    \"#AAAAAA\",  # symbol_5: grey\n",
    "    \"#F012BE\",  # symbol_6: fuschia\n",
    "    \"#FF851B\",  # symbol_7: orange\n",
    "    \"#7FDBFF\",  # symbol_8: teal\n",
    "    \"#870C25\"   # symbol_9: brown\n",
    "])\n",
    "\n",
    "obj = all_preds  # or load the raw file you saved before building all_preds\n",
    "print(type(obj))\n",
    "print(list(obj.keys()) if hasattr(obj, \"keys\") else obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'puzzle_identifiers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 175\u001b[39m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Ks):\n\u001b[32m    172\u001b[39m         \u001b[38;5;28mprint\u001b[39m (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-shot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect[i]\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(puzzle_labels)\u001b[38;5;250m \u001b[39m*\u001b[38;5;250m \u001b[39m\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mtest\u001b[39m\u001b[34m(visualize, Ks)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtest\u001b[39m(visualize, Ks=[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m1000\u001b[39m]):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     identifier_map, all_preds = \u001b[43mload_identifiers_and_preds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATASET_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHECKPOINT_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     global_hmap = {}\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# Get puzzles and corresponding answers\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mload_identifiers_and_preds\u001b[39m\u001b[34m(dataset_path, checkpoint_path)\u001b[39m\n\u001b[32m     16\u001b[39m all_preds = {k: torch.cat(v, dim=\u001b[32m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m all_preds.items()}\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Remove paddings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m mask = \u001b[43mall_preds\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpuzzle_identifiers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m != PAD_PUZZLE_IDENTIFIER\n\u001b[32m     20\u001b[39m all_preds = {k: v[mask] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m all_preds.items()}\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m identifier_map, all_preds\n",
      "\u001b[31mKeyError\u001b[39m: 'puzzle_identifiers'"
     ]
    }
   ],
   "source": [
    "def load_identifiers_and_preds(dataset_path: str, checkpoint_path: str):\n",
    "    # Load puzzle identifiers\n",
    "    with open(os.path.join(dataset_path, \"identifiers.json\"), \"r\") as f:\n",
    "        identifier_map = json.load(f)\n",
    "        \n",
    "    # Load preds\n",
    "    all_preds = {}\n",
    "    for filename in glob(f\"{checkpoint_path}_all_preds.*\"):\n",
    "        preds = torch.load(filename)\n",
    "        for k, v in preds.items():\n",
    "            all_preds.setdefault(k, [])\n",
    "            all_preds[k].append(v)\n",
    "            \n",
    "        del preds\n",
    "\n",
    "    all_preds = {k: torch.cat(v, dim=0) for k, v in all_preds.items()}\n",
    "    \n",
    "    # Remove paddings\n",
    "    mask = all_preds[\"puzzle_identifiers\"] != PAD_PUZZLE_IDENTIFIER\n",
    "    all_preds = {k: v[mask] for k, v in all_preds.items()}\n",
    "\n",
    "    return identifier_map, all_preds\n",
    "\n",
    "\n",
    "def inverse_aug(name: str, grid: np.ndarray):\n",
    "    if \"_\" not in name:\n",
    "        return grid\n",
    "\n",
    "    trans_id, perm = name.split(\"_\")[-2:]\n",
    "    trans_id = int(trans_id[1:])  # Remove \"t\" letter\n",
    "    inv_perm = np.argsort(list(perm))\n",
    "    \n",
    "    return inv_perm[inverse_dihedral_transform(grid, trans_id)]\n",
    "\n",
    "\n",
    "def grid_hash(grid: np.ndarray):\n",
    "    return hash((grid.tobytes(), grid.shape))\n",
    "\n",
    "\n",
    "@njit\n",
    "def crop(grid: np.ndarray):\n",
    "    # Find maximum-sized rectangle without any EOS token inside.\n",
    "    grid = grid.reshape(30, 30)\n",
    "\n",
    "    max_area = 0\n",
    "    max_size = (0, 0)\n",
    "    nr, nc = grid.shape\n",
    "    \n",
    "    num_c = nc\n",
    "    for num_r in range(1, nr + 1):\n",
    "        # Scan for maximum c\n",
    "        for c in range(1, num_c + 1):\n",
    "            x = grid[num_r - 1, c - 1]\n",
    "            if (x < 2) | (x > 11):\n",
    "                num_c = c - 1\n",
    "                break\n",
    "        \n",
    "        area = num_r * num_c\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            max_size = (num_r, num_c)\n",
    "\n",
    "    return grid[:max_size[0], :max_size[1]] - 2\n",
    "\n",
    "\n",
    "def test(visualize, Ks=[1, 2, 10, 100, 1000]):\n",
    "    identifier_map, all_preds = load_identifiers_and_preds(DATASET_PATH, CHECKPOINT_PATH)\n",
    "    \n",
    "    global_hmap = {}\n",
    "    \n",
    "    # Get puzzles and corresponding answers\n",
    "    puzzle_labels = {}\n",
    "    for identifier, input, label in zip(all_preds[\"puzzle_identifiers\"], all_preds[\"inputs\"], all_preds[\"labels\"]):\n",
    "        name = identifier_map[identifier]\n",
    "        if \"_\" not in name:   # Not-augmented\n",
    "            puzzle_labels.setdefault(name, {})\n",
    "            \n",
    "            input = crop(input.numpy())\n",
    "            label = crop(label.numpy())\n",
    "\n",
    "            input_hash = grid_hash(input)\n",
    "            label_hash = grid_hash(label)\n",
    "\n",
    "            global_hmap[input_hash] = input\n",
    "            global_hmap[label_hash] = label\n",
    "\n",
    "            assert input_hash not in puzzle_labels[name]\n",
    "            puzzle_labels[name][input_hash] = label_hash\n",
    "            \n",
    "    print (\"Number of puzzles\", len(puzzle_labels))\n",
    "    \n",
    "    # Argmax prediction\n",
    "    preds = all_preds[\"logits\"].argmax(-1)\n",
    "\n",
    "    # Collate\n",
    "    pred_answers = {}\n",
    "    for identifier, input, pred, q in zip(all_preds[\"puzzle_identifiers\"], all_preds[\"inputs\"], preds, all_preds[\"q_halt_logits\"].sigmoid()):\n",
    "        name = identifier_map[identifier]\n",
    "        orig_name = name.split(\"_\")[0]\n",
    "        \n",
    "        input = input.numpy()\n",
    "        input_hash = grid_hash(inverse_aug(name, crop(input)))\n",
    "        assert input_hash in puzzle_labels[orig_name]\n",
    "        \n",
    "        pred = inverse_aug(name, crop(pred.numpy()))\n",
    "        pred_hash = grid_hash(pred)\n",
    "        global_hmap[pred_hash] = pred\n",
    "        \n",
    "        pred_answers.setdefault(orig_name, {})\n",
    "        pred_answers[orig_name].setdefault(input_hash, [])\n",
    "        pred_answers[orig_name][input_hash].append((pred_hash, q.item()))\n",
    "\n",
    "    # test-1\n",
    "    if visualize:\n",
    "        num_figs = sum(len(tests) for name, tests in puzzle_labels.items())\n",
    "        fig, axes = plt.subplots(num_figs, 4, figsize=(8, num_figs * 4))\n",
    "        \n",
    "        fig_id = 0\n",
    "    \n",
    "    correct = [0 for _ in range(len(Ks))]\n",
    "    for name, tests in puzzle_labels.items():\n",
    "        num_test_correct = [0 for _ in range(len(Ks))]\n",
    "        for input_hash, label_hash in tests.items():\n",
    "            p = pred_answers[name][input_hash]\n",
    "            p_map = {}\n",
    "            \n",
    "            for h, q in p:\n",
    "                p_map.setdefault(h, [0, 0])\n",
    "                p_map[h][0] += 1\n",
    "                p_map[h][1] += q\n",
    "                \n",
    "            for h, stats in p_map.items():\n",
    "                stats[1] /= stats[0]\n",
    "                \n",
    "            p_map = sorted(p_map.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "            # 2-vote\n",
    "            for i, k in enumerate(Ks):\n",
    "                ok = False\n",
    "                for h, stats in p_map[:k]:\n",
    "                    ok |= h == label_hash\n",
    "                    \n",
    "                num_test_correct[i] += ok\n",
    "\n",
    "            if visualize:\n",
    "                # Show input and ground truth\n",
    "                axes[fig_id, 0].imshow(global_hmap[input_hash], cmap=ARC_COLOR_MAP)\n",
    "                axes[fig_id, 0].set_title(f\"{name}\\nInput\")\n",
    "                axes[fig_id, 0].axis('off')\n",
    "                \n",
    "                axes[fig_id, 1].imshow(global_hmap[label_hash], cmap=ARC_COLOR_MAP)\n",
    "                axes[fig_id, 1].set_title(f\"{name}\\nAnswer\")\n",
    "                axes[fig_id, 1].axis('off')\n",
    "                \n",
    "                trial_id = 2\n",
    "                for h, stats in p_map[:2]:\n",
    "                    ans = global_hmap[h]\n",
    "                    \n",
    "                    axes[fig_id, trial_id].imshow(ans, cmap=ARC_COLOR_MAP)\n",
    "                    axes[fig_id, trial_id].set_title(f\"{name}\\nTrial {trial_id}\")\n",
    "                    axes[fig_id, trial_id].axis('off')\n",
    "                    \n",
    "                    trial_id += 1\n",
    "                \n",
    "                fig_id += 1\n",
    "            \n",
    "        # Total correctness\n",
    "        for i in range(len(Ks)):\n",
    "            correct[i] += num_test_correct[i] == len(tests)\n",
    "\n",
    "    for i, k in enumerate(Ks):\n",
    "        print (f\"{k}-shot: {correct[i] / len(puzzle_labels) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "test(visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
